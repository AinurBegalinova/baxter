{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow as tf \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "import random\n",
    "import shutil\n",
    "import tensorflow.contrib.learn as tflearn\n",
    "import tensorflow.contrib.layers as tflayers\n",
    "from tensorflow.contrib.learn.python.learn import learn_runner\n",
    "import tensorflow.contrib.metrics as metrics \n",
    "import tensorflow.contrib.rnn as rnn \n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'DATASET/'\n",
    "TRAIN = 'traj_1_train_shuffled.csv'\n",
    "TEST = 'traj_1_test_shuffled.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CSV Data...\n",
      "(35, 85)\n"
     ]
    }
   ],
   "source": [
    "print('Reading CSV Data...')\n",
    "df = pd.read_csv(PATH + TRAIN)\n",
    "test_df = pd.read_csv(PATH + TEST)\n",
    "\n",
    "#Create a new feature for normal (non-fraudulent) transactions.\n",
    "df.loc[df.label == 0, 'Slip'] = 1\n",
    "df.loc[df.label == 1, 'Slip'] = 0\n",
    "\n",
    "test_df.loc[test_df.label == 0, 'Slip'] = 1\n",
    "test_df.loc[test_df.label == 1, 'Slip'] = 0\n",
    "\n",
    "#Rename 'Class' to 'Fraud'.\n",
    "df = df.rename(columns={'label': 'Stable'})\n",
    "test_df = test_df.rename(columns={'label': 'Stable'})\n",
    "\n",
    "#Create dataframes of only Fraud and Normal transactions.\n",
    "Slip = df[df.Slip == 1]\n",
    "Stable = df[df.Stable == 1]\n",
    "\n",
    "test_Slip = test_df[test_df.Slip == 1]\n",
    "test_Stable = test_df[test_df.Stable == 1]\n",
    "\n",
    "# Set X_train equal to 80% of the fraudulent transactions.\n",
    "#X_train = Slip.sample\n",
    "#count_Slips = len(Slip)\n",
    "\n",
    "# Add 80% of the normal transactions to X_train.\n",
    "X_train = pd.concat([Slip, Stable], axis = 0)\n",
    "X_test = pd.concat([test_Slip, test_Stable], axis = 0)\n",
    "\n",
    "# X_test contains all the transaction not in X_train.\n",
    "#X_test = df.loc[~df.index.isin(X_train.index)]\n",
    "\n",
    "#Shuffle the dataframes so that the training is done in a random order.\n",
    "X_train = shuffle(X_train)\n",
    "X_test = shuffle(test_df)\n",
    "\n",
    "#Add our target features to y_train and y_test.\n",
    "y_train = X_train.Slip\n",
    "y_train = pd.concat([y_train, X_train.Stable], axis=1)\n",
    "\n",
    "y_test = X_test.Slip\n",
    "y_test = pd.concat([y_test, X_test.Stable], axis=1)\n",
    "\n",
    "#Drop target features from X_train and X_test.\n",
    "X_train = X_train.drop(['Slip','Stable'], axis = 1)\n",
    "X_test = X_test.drop(['Slip','Stable'], axis = 1)\n",
    "\n",
    "\n",
    "#Select certain features\n",
    "#cols = [c for c in X_train.columns if c.lower()[:5] != 'median']\n",
    "X_train = X_train[X_train.columns.drop(list(X_train.filter(regex='left')))]\n",
    "X_test = X_test[X_test.columns.drop(list(X_test.filter(regex='left')))]\n",
    "\n",
    "#X_train = X_train[X_train.columns.drop(list(X_train.filter(regex='right')))]\n",
    "#X_test = X_test[X_test.columns.drop(list(X_test.filter(regex='right')))]\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "\n",
    "#X_train = X_train[:, 3]\n",
    "#y_train = y_train[:, 1]\n",
    "\n",
    "#X_test = X_test[:, 3]\n",
    "#y_test = y_test [:, 1]\n",
    "print (X_test.shape)\n",
    "#print (y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.02\n",
    "training_epochs = 10000\n",
    "batch_size = 128\n",
    "display_step = 2\n",
    "\n",
    "# Network Parameters\n",
    "num_input = X_train[0, :].size\n",
    "print (num_input)\n",
    "timesteps = 1\n",
    "num_hidden = int(X_train[0, :].size * .5)\n",
    "num_classes = 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.reset_default_graph()\n",
    "\n",
    "\n",
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    with tf.variable_scope('lstm1'):\n",
    "        outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "logits = RNN(X, weights, biases)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_summary = [] # Record accuracy values for plot\n",
    "cost_summary = [] # Record cost values for plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Finished!\n",
      "[[]]\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "    \n",
    "    accuracy_summary.append([])\n",
    "    cost_summary.append([])\n",
    "    \n",
    "    for epoch in range(1, training_epochs+1):\n",
    "        \n",
    "        for batch in range(int(num_input/batch_size)):\n",
    "            batch_x = X_train[batch*batch_size : (1+batch)*batch_size]\n",
    "            batch_y = y_train[batch*batch_size : (1+batch)*batch_size]\n",
    "            \n",
    "            batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "            #print (\"Batch shape\", batch_x.shape)\n",
    "            # Run optimization op (backprop)\n",
    "            sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "            \n",
    "            if epoch % display_step == 0 or epoch == 1:\n",
    "                # Calculate batch loss and accuracy\n",
    "                loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x, Y: batch_y})\n",
    "                \n",
    "                accuracy_summary[-1].append(acc)\n",
    "                cost_summary[-1].append(loss)\n",
    "                #print(\"Step \" + str(epoch) + \", Minibatch Loss= \" + \\\n",
    "                 #     \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  #    \"{:.3f}\".format(acc))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for test data\n",
    "    test_len = 22\n",
    "    test_data = X_test[:test_len].reshape((-1, timesteps, num_input))\n",
    "    test_label = y_test[:test_len]\n",
    "    print (accuracy_summary)\n",
    "    #print(\"Testing Accuracy:\", \\\n",
    "       # sess.run(accuracy, feed_dict={X: test_data, Y: test_label}))\n",
    "    \n",
    "    #print (prediction.eval(feed_dict = {X: test_data, Y: test_label}))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "integer division or modulo by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-cb3f31551fd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_summary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'training'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# green\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0max2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost_summary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'green'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ainur/tensorflow/lib/python2.7/site-packages/matplotlib/__init__.pyc\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1708\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1709\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1710\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1711\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ainur/tensorflow/lib/python2.7/site-packages/matplotlib/axes/_axes.pyc\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1435\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1437\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1438\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1439\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ainur/tensorflow/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ainur/tensorflow/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mncx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mncx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0mseg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mncx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mncy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m             \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: integer division or modulo by zero"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119a26b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#fig = dict(data=data, layout=layout)\n",
    "\n",
    "#py.iplot(fig, filename='Sine Wave Slider')\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(10,6))\n",
    "ax1.plot(accuracy_summary, color = 'blue',  label = 'training') # green\n",
    "ax1.set_title('Accuracy')\n",
    "ax2.plot(cost_summary, color = 'green',  label = 'training')\n",
    "ax2.set_title('Cost')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=1, borderaxespad=0.)\n",
    "plt.xlabel('Epochs (x10)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
